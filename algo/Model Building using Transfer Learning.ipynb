{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 01 : Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"Bread\", \"Dairy product\", \"Dessert\", \n",
    "           \"Egg\",   \"Fried food\",    \"Meat\", \n",
    "           \"Noodles-Pasta\", \"Rice\",  \"Seafood\", \n",
    "           \"Soup\",  \"Vegetable-Fruit\"\n",
    "          ]\n",
    "\n",
    "dataDir = \"//kaggle//input//food11-image-dataset//\"\n",
    "trainDir = \"//kaggle//input//food11-image-dataset//training//**\"\n",
    "testDir = \"//kaggle//input//food11-image-dataset//evaluation//**\"\n",
    "valDir = \"//kaggle//input//food11-image-dataset//validation//**\"\n",
    "\n",
    "img_shape = (224, 224, 3)\n",
    "\n",
    "totalTrain = len([1 for i in glob.iglob(trainDir, recursive=True) if os.path.isfile(i)])\n",
    "totalVal   = len([1 for i in glob.iglob(valDir,   recursive=True) if os.path.isfile(i)])\n",
    "totalTest  = len([1 for i in glob.iglob(testDir,  recursive=True) if os.path.isfile(i)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 02 : Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Data Generator\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "valAug = ImageDataGenerator()\n",
    "\n",
    "# Apply a Processing Technique on Data : Pixel Subtraction\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean\n",
    "\n",
    "\n",
    "# Initialize Data Generators\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    directory= dataDir + \"training\",\n",
    "    class_mode= \"categorical\",\n",
    "    target_size= img_shape[0:2],\n",
    "    color_mode= \"rgb\",\n",
    "    shuffle= True,\n",
    "    batch_size= 32)\n",
    "\n",
    "valGen = valAug.flow_from_directory(\n",
    "    directory= dataDir + \"validation\",\n",
    "    class_mode= \"categorical\",\n",
    "    target_size= img_shape[0:2],\n",
    "    color_mode= \"rgb\",\n",
    "    shuffle= False,\n",
    "    batch_size= 32)\n",
    "\n",
    "testGen = valAug.flow_from_directory(\n",
    "    directory= dataDir + \"evaluation\",\n",
    "    class_mode= \"categorical\",\n",
    "    target_size= img_shape[0:2],\n",
    "    color_mode= \"rgb\",\n",
    "    shuffle= False,\n",
    "    batch_size= 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 03 : Model Training using Transfer Learning\n",
    "\n",
    "### Part 01 : Model Warm Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(img_shape, base):\n",
    "    headModel = base.output\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(len(CLASSES), activation=\"softmax\")(headModel)\n",
    "    model = Model(inputs=base.input, outputs=headModel)\n",
    "    opt = SGD(lr=1e-4, momentum=0.9)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def plot_history(N, title):\n",
    "    plt.figure()\n",
    "    plt.plot(N.history[\"loss\"], label=\"training loss\", color =\"b\", marker='x')\n",
    "    plt.plot(N.history[\"val_loss\"], label=\"validation loss\", color =\"g\", marker='x')\n",
    "    plt.plot(N.history[\"accuracy\"], label=\"training accuracy\", color=\"lightgrey\")\n",
    "    plt.plot(N.history[\"val_accuracy\"], label=\"validation accuracy\", color=\"r\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"accuracy/loss\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=img_shape), pooling=\"max\")\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = create_model(img_shape, baseModel)\n",
    "\n",
    "H = model.fit_generator(\n",
    "    trainGen,\n",
    "    steps_per_epoch= totalTrain // 32,\n",
    "    validation_data= valGen,\n",
    "    validation_steps= totalVal // 32,\n",
    "    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"warmup_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(H, \"History of VGG16 Model : Warm Up\")\n",
    "testGen.reset()\n",
    "\n",
    "test_history = model.predict_generator(\n",
    "    testGen,\n",
    "    steps=(totalTest//32)+1\n",
    ")\n",
    "\n",
    "predicted_class_indices = np.argmax(test_history,axis=1)\n",
    "\n",
    "report = classification_report(\n",
    "    testGen.classes, \n",
    "    predicted_class_indices, \n",
    "    target_names=testGen.class_indices.keys())\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 02 : Adjust Model Original Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Data Generators\n",
    "trainGen.reset()\n",
    "valGen.reset()\n",
    "\n",
    "for layer in baseModel.layers[15:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model = create_model(img_shape, baseModel)\n",
    "\n",
    "H = model.fit_generator(\n",
    "    trainGen,\n",
    "    steps_per_epoch= totalTrain // 32,\n",
    "    validation_data= valGen,\n",
    "    validation_steps= totalVal // 32,\n",
    "    epochs= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(H, \"History of VGG16 Model : Adjusting Weights\")\n",
    "testGen.reset()\n",
    "\n",
    "test_history = model.predict_generator(\n",
    "    testGen,\n",
    "    steps=(totalTest//32)+1\n",
    ")\n",
    "\n",
    "predicted_class_indices = np.argmax(test_history,axis=1)\n",
    "\n",
    "report = classification_report(\n",
    "    testGen.classes, \n",
    "    predicted_class_indices, \n",
    "    target_names=testGen.class_indices.keys())\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"adjust_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 04 : Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"bread_features.joblib\",  \"dairy_features.joblib\",     \"dessert_features.joblib\", \n",
    "           \"egg_features.joblib\",    \"friedfood_features.joblib\", \"meat_features.joblib\",\n",
    "           \"pasta_features.joblib\",  \"rice_features.joblib\",      \"seafood_features.joblib\",   \n",
    "           \"soup_features.joblib\",   \"fruit_features.joblib\"]\n",
    "\n",
    "def preprocess_image(path, shape):\n",
    "    image = load_img(path, target_size=shape)\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def extractor(path, model, shape):\n",
    "    feats = []\n",
    "    names = [] \n",
    "    for imgname in os.listdir(path):\n",
    "        image = preprocess_image(os.path.join(path, imgname), shape)\n",
    "        feat  = model.predict(image)\n",
    "        feat  = np.array(feat)\n",
    "        names.append(imgname)\n",
    "        feats.append(feat.flatten())\n",
    "\n",
    "    return np.array(names), np.array(feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"//kaggle//input//food11cbir//food11CBIR//\"\n",
    "\n",
    "i = 0\n",
    "for folder in os.listdir(dataDir):\n",
    "    embedding = extractor(os.path.join(dataDir, folder), baseModel, img_shape)\n",
    "    joblib.dump(embedding, os.path.join(\"//kaggle//working//embeddings\", FEATURES[i]), compress=True)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 05 : Approximate Nearest Neighbor Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEXES = [\"breadIndex.ann\",  \"dairyIndex.ann\",     \"dessertIndex.ann\", \n",
    "           \"eggIndex.ann\",    \"friedfoodIndex.ann\", \"meatIndex.ann\",\n",
    "           \"pastaIndex.ann\",  \"riceIndex.ann\",      \"seafoodIndex.ann\",   \n",
    "           \"soupIndex.ann\",   \"fruitIndex.ann\"]\n",
    "\n",
    "\n",
    "for i in range(11):\n",
    "    index = AnnoyIndex(512, \"euclidean\")\n",
    "    names, embs = joblib.load(os.path.join(\"//kaggle//input//embeddings\", FEATURES[i]))\n",
    "    for j in range(len(names)):\n",
    "        index.add_item(j, embs[j]) \n",
    "    \n",
    "    index.build(7) \n",
    "    index.save(os.path.join(\"annoy_indexes\", INDEXES[i]), prefault=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}